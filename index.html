<!DOCTYPE html>
<html>

<head>
    <title>
        mjksmith
    </title>
    <link rel="stylesheet" type="text/css" href="style.css" />
</head>

<body>
    <h1>Matt Smith</h1>
    <div id="intro">
    <p>
        2019 UWaterloo Honours BMath with Distinction (Dean's Honours List) in CS and C&amp;O. <br />
        Former VP of Education for UWaterloo Data Science Club (DSC). <br />
        Machine Learning Engineer at Yelp (2019-present).
    <p>
        <a href="https://www.linkedin.com/in/mjksmith/">My LinkedIn</a>
    </p>
    </div>

    <h2>Summary of Talks</h2>
    <div id="talks">

        <div class="talk">
        <h3>Guest Lecture @ Make School</h3>
        <p><a href="https://www.makeschool.com/">Make School</a> at 1:15 on 2020-02-20</p>
        <p>Please contact me if you want the slides.</p>
        </div>

        <div class="talk">
        <h3>DSC Transformer & Attention Workshop</h3>
        <p>MC4045 at 6:30 on 2019-04-03</p>
        <ul>
            <li><a href="DSC_Transformer_Presentation.pdf">Slides</a></li>
        </ul>
        </div>

        <div class="talk">
        <h3>NLP Reading Group</h3>
        <p>
            Meets in MC4042 at 4:30-5:30 every Thursday.
        </p>
        <p>
        <b>UPDATE:</b> NLP Reading Group is now finished. Thank you for attending! :)
        </p>

        <h4>Meeting 5 (2019-04-04)</h4>
        <p>
            Paper coverage:
        </p>
        <ul>
            <li><a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></li>
            <li><a href="https://cs.stanford.edu/people/karpathy/cvpr2015.pdf">Deep Visual-Semantic Alignments for Generating Image Descriptions</a></li>
            <li><a href="https://arxiv.org/abs/1901.02860">Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context</a></li>
            <li><a href="https://arxiv.org/abs/1901.11117">The Evolved Transformer</a></li>
            <li><a href="https://arxiv.org/abs/1807.03819">Universal Transformers</a></li>
        </ul>
        <p>
            Links:
        </p>
        <ul>
            <li><a href="NLP_Reading_Group_5.pdf">Slides</a></li>
            <li><a href="https://twitter.com/OriolVinyalsML/status/1017523208059260929">Universal Transformer Animation</a></li>
        </ul>

        <h4>Meeting 4 (2019-03-21)</h4>
        <p>
            Paper coverage:
        </p>
        <ul>
            <li><a href="https://arxiv.org/abs/1802.05365">Deep contextualized word representations</a></li>
            <li><a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></li>
            <li><a href="https://cs.stanford.edu/people/karpathy/cvpr2015.pdf">Deep Visual-Semantic Alignments for Generating Image Descriptions</a></li>
        </ul>
        <p>
            Links:
        </p>
        <ul>
            <li><a href="NLP_Reading_Group_4.pdf">Slides</a></li>
        </ul>

        <h4>Meeting 3 (2019-03-14)</h4>
        <p>
            Paper coverage:
        </p>
        <ul>
            <li><a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a></li>
            <li><a href="https://arxiv.org/abs/1508.06615">Character-Aware Neural Language Models</a></li>
            <li><a href="https://arxiv.org/abs/1802.05365">Deep contextualized word representations</a></li>
            <li><a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></li>
        </ul>
        <p>
            Links:
        </p>
        <ul>
            <li><a href="NLP_Reading_Group_3.pdf">Slides</a></li>
        </ul>
        
        <h4>Meeting 2 (2019-03-07)</h4>
        <p>
            Paper coverage:
        </p>
        <ul>
            <li><a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a></li>
            <li><a href="https://www.cs.cmu.edu/~hovy/papers/16HLT-hierarchical-attention-networks.pdf">Hierarchical Attention Networks for Document Classification</a></li>
            <li><a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a></li>
            <li><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">Improving Language Understanding by Generative Pre-Training</a></li>
        </ul>
        <p>
            Links:
        </p>
        <ul>
            <li><a href="NLP_Reading_Group_2.pdf">Slides</a></li>
            <li><a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html">Attention? Attention by Lilian Weng</a></li>
            <li><a href="https://blog.openai.com/language-unsupervised/">GPT-1 Blog Post</a></li>
            <li><a href="https://blog.openai.com/better-language-models/">GPT-2 Blog Post</a></li>
        </ul>

        <h4>Meeting 1 (2019-02-28)</h4>
        <p>
            Paper coverage:
        </p>
        <ul>
            <li><a href="http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf">A Neural Probabilistic Language Model</a></li>
            <li><a href="https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/">word2vec -- The amazing power of word vectors</a></li>
            <li><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a></li>
            <li><a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Recurrent Neural Networks</a></li>
        </ul>
        <p>
            Links:
        </p>
        <ul>
            <li><a href="NLP_Reading_Group_1.pdf">Slides</a></li>
            <li><a href="https://github.com/mjksmith/mjksmith.github.io/tree/master/music">Music generated with char-lstm</a></li>
        </ul>
        </div>

        <div class="talk">
        <h3>NLP Workshop</h3>
        <ul>
            <li><a href="https://colab.research.google.com/drive/1rZD_aHDh7riOLvTVLulM-uHLV2prnpB1">Starter notebook</a></li>
            <li><a href="https://colab.research.google.com/drive/1JIRvbQUMAzHbq95i-SfhJ77O_Y7GdNQd">Backup (completed) notebook</a></li>
            <li><a href="NLP_Workshop.pdf">Slides</a></li>
        </ul>
        </div>

        <div class="talk">
        <h3>Popular Dishes Presentation</h3>
        <p>
        <a href="Waterloo_DSC_Pop_Dishes.pdf">Slides</a>
        </p>
        </div>

    </div>

</body>

</html>
